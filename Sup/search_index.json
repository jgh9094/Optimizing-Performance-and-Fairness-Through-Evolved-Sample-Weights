[["index.html", "Supplemental Material for ‘Optimizing Model Performance and Fairness Through Genetically Evolved Sample Weights’ Chapter 1 Introduction 1.1 Contributing authors 1.2 About our supplemental material 1.3 Supplemental material setup", " Supplemental Material for ‘Optimizing Model Performance and Fairness Through Genetically Evolved Sample Weights’ Anil Kumar Saini, Jose Guadalupe Hernandez, Emily F. Wong, Jason H. Moore 2024-07-15 Chapter 1 Introduction This is not intended as a stand-alone document, but as a companion to our manuscript. 1.1 Contributing authors Anil Kumar Saini Jose Guadalupe Hernandez Emily F. Wong Jason H. Moore 1.2 About our supplemental material As you may have noticed (unless you’re reading a pdf version of this), our supplemental material is hosted using GitHub pages. We compiled our data analyses and supplemental documentation into this nifty web-accessible book using bookdown. The code used for this supplemental material can be found in this GitHub repository. Our supplemental material includes the following: Heart disease results (Section 2) Student math results (Section 3) Student por results (Section 4) CreditG results (Section 5) Titanic results (Section 6) US Crime results (Section 7) Compas Violent results (Section 8) NLSY results (Section 9) Compas results (Section 10) Speed dating results (Section 11) 1.3 Supplemental material setup 1.3.1 Required packages and variables Variable set up. library(ggplot2) library(cowplot) library(dplyr) library(PupillometryR) NAMES &lt;- c(&#39;Evolved&#39;,&#39;Calculated&#39;,&#39;None&#39;) TASKS &lt;- c(&#39;heart_disease&#39;, &#39;student_math&#39;, &#39;student_por&#39;, &#39;creditg&#39;, &#39;titanic&#39;, &#39;us_crime&#39;, &#39;compas_violent&#39;, &#39;nlsy&#39;, &#39;compas&#39;, &#39;speeddating&#39;) SHAPE &lt;- c(21,24,22) cb_palette &lt;- c(&#39;#D81B60&#39;,&#39;#1E88E5&#39;,&#39;#FFC107&#39;) TSIZE &lt;- 19 p_theme &lt;- theme( plot.title = element_text( face = &quot;bold&quot;, size = 22, hjust=0.5), panel.border = element_blank(), panel.grid.minor = element_blank(), legend.title=element_text(size=18), legend.text=element_text(size=18), axis.title = element_text(size=18), axis.text = element_text(size=14), legend.position=&quot;bottom&quot;, panel.background = element_rect(fill = &quot;#f1f2f5&quot;, colour = &quot;white&quot;, linewidth = 0.5, linetype = &quot;solid&quot;) ) testing &lt;- read.csv(paste(&#39;./&#39;, &#39;hv_test.csv&#39;, sep = &quot;&quot;, collapse = NULL), header = TRUE, stringsAsFactors = FALSE) testing$exp &lt;- gsub(&#39;Evolved Weights&#39;, &#39;Evolved&#39;, testing$ex) testing$exp &lt;- gsub(&#39;Calculated Weights&#39;, &#39;Calculated&#39;, testing$ex) testing$exp &lt;- gsub(&#39;No Weights&#39;, &#39;None&#39;, testing$ex) testing$exp &lt;- factor(testing$exp, levels = NAMES) 1.3.2 Helper functions Function to plot hypervolume results # function to plot hyper-volume data volume_plotter &lt;- function(data, id) { ggplot(data, aes(x = exp, y = hv, color = exp, fill = exp, shape = exp)) + geom_flat_violin(position = position_nudge(x = .1, y = 0), scale = &#39;width&#39;, alpha = 0.2, width = 1.5) + geom_boxplot(color = &#39;black&#39;, width = .07, outlier.shape = NA, alpha = 0.0, size = 1.0, position = position_nudge(x = .18, y = 0)) + geom_point(position = position_jitter(width = 0.02, height = 0.0001), size = 1.5, alpha = 1.0) + scale_y_continuous( name=&quot;Volume&quot;, ) + scale_x_discrete( name=&quot;Strategy&quot; )+ scale_shape_manual(values=SHAPE, name=&quot;Weight\\nStrategy&quot;) + scale_colour_manual(values = cb_palette, name=&quot;Weight\\nStrategy&quot;) + scale_fill_manual(values = cb_palette, name=&quot;Weight\\nStrategy&quot;) + ggtitle(TASKS[id])+ p_theme + coord_flip() } Function to summarize hypervolume results # function to plot hyper-volume data volume_summarize &lt;- function(data) { data %&gt;% group_by(exp) %&gt;% dplyr::summarise( count = n(), na_cnt = sum(is.na(hv)), min = min(hv, na.rm = TRUE), median = median(hv, na.rm = TRUE), mean = mean(hv, na.rm = TRUE), max = max(hv, na.rm = TRUE), IQR = IQR(hv, na.rm = TRUE) ) } "],["heart-disease.html", "Chapter 2 Heart Disease 2.1 Analysis setup 2.2 Hypervolume", " Chapter 2 Heart Disease Here we report the hypervolume achived by evaluating the performance of each solution wihtin the Pareto front on the test set of the heart_disease dataset. 2.1 Analysis setup # heart-disease data data &lt;- filter(testing, dataset == &quot;heart_disease&quot;) 2.2 Hypervolume volume_plotter(data,1) 2.2.1 Summary stats volume_summarize(data) ## # A tibble: 3 × 8 ## exp count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Evolved 20 0 0.134 0.5 0.417 0.519 0.141 ## 2 Calculated 20 0 0.0695 0.119 0.125 0.213 0.0633 ## 3 None 20 0 0.0722 0.118 0.126 0.221 0.0613 2.2.2 Kruskal-Wallis test Detected differences between weight strategies. kruskal.test(hv ~ exp, data = data) ## ## Kruskal-Wallis rank sum test ## ## data: hv by exp ## Kruskal-Wallis chi-squared = 34.987, df = 2, p-value = 2.528e-08 2.2.3 Pairwise wlcoxon test pairwise.wilcox.test(x = data$hv, g = data$exp, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: data$hv and data$exp ## ## Evolved Calculated ## Calculated 4.5e-07 - ## None 4.5e-07 1 ## ## P value adjustment method: bonferroni "],["student-math.html", "Chapter 3 Student Math 3.1 Analysis setup 3.2 Hypervolume", " Chapter 3 Student Math Here we report the hypervolume achived by evaluating the performance of each solution wihtin the Pareto front on the test set of the student_math dataset. 3.1 Analysis setup # heart-disease data data &lt;- filter(testing, dataset == &quot;student_math&quot;) 3.2 Hypervolume volume_plotter(data,2) 3.2.1 Summary stats volume_summarize(data) ## # A tibble: 3 × 8 ## exp count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Evolved 20 0 0.0594 0.323 0.308 0.5 0.255 ## 2 Calculated 20 0 0.0129 0.0448 0.0504 0.0873 0.0307 ## 3 None 20 0 0.0116 0.0441 0.0503 0.0939 0.0326 3.2.2 Kruskal-Wallis test Detected differences between weight strategies. kruskal.test(hv ~ exp, data = data) ## ## Kruskal-Wallis rank sum test ## ## data: hv by exp ## Kruskal-Wallis chi-squared = 36.282, df = 2, p-value = 1.323e-08 3.2.3 Pairwise wlcoxon test pairwise.wilcox.test(x = data$hv, g = data$exp, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: data$hv and data$exp ## ## Evolved Calculated ## Calculated 3.3e-07 - ## None 3.3e-07 1 ## ## P value adjustment method: bonferroni "],["student-por.html", "Chapter 4 Student Por 4.1 Analysis setup 4.2 Hypervolume", " Chapter 4 Student Por Here we report the hypervolume achived by evaluating the performance of each solution wihtin the Pareto front on the test set of the student_por dataset. 4.1 Analysis setup # heart-disease data data &lt;- filter(testing, dataset == &quot;student_por&quot;) 4.2 Hypervolume volume_plotter(data,3) 4.2.1 Summary stats volume_summarize(data) ## # A tibble: 3 × 8 ## exp count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Evolved 20 0 0.128 0.288 0.318 0.5 0.123 ## 2 Calculated 20 0 0.0168 0.0546 0.0528 0.0878 0.0286 ## 3 None 20 0 0.0181 0.0573 0.0547 0.0851 0.0298 4.2.2 Kruskal-Wallis test Detected differences between weight strategies. kruskal.test(hv ~ exp, data = data) ## ## Kruskal-Wallis rank sum test ## ## data: hv by exp ## Kruskal-Wallis chi-squared = 39.429, df = 2, p-value = 2.742e-09 4.2.3 Pairwise wlcoxon test pairwise.wilcox.test(x = data$hv, g = data$exp, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: data$hv and data$exp ## ## Evolved Calculated ## Calculated 1e-07 - ## None 1e-07 1 ## ## P value adjustment method: bonferroni "],["creditg.html", "Chapter 5 CreditG 5.1 Analysis setup 5.2 Hypervolume", " Chapter 5 CreditG Here we report the hypervolume achived by evaluating the performance of each solution wihtin the Pareto front on the test set of the creditg dataset. 5.1 Analysis setup # heart-disease data data &lt;- filter(testing, dataset == &quot;creditg&quot;) 5.2 Hypervolume volume_plotter(data,4) 5.2.1 Summary stats volume_summarize(data) ## # A tibble: 3 × 8 ## exp count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Evolved 20 0 0.199 0.467 0.443 0.565 0.112 ## 2 Calculated 20 0 0.186 0.260 0.252 0.302 0.0477 ## 3 None 20 0 0.187 0.259 0.253 0.305 0.0450 5.2.2 Kruskal-Wallis test Detected differences between weight strategies. kruskal.test(hv ~ exp, data = data) ## ## Kruskal-Wallis rank sum test ## ## data: hv by exp ## Kruskal-Wallis chi-squared = 32.972, df = 2, p-value = 6.922e-08 5.2.3 Pairwise wlcoxon test pairwise.wilcox.test(x = data$hv, g = data$exp, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: data$hv and data$exp ## ## Evolved Calculated ## Calculated 1.1e-06 - ## None 1.1e-06 1 ## ## P value adjustment method: bonferroni "],["titanic.html", "Chapter 6 Titanic 6.1 Analysis setup 6.2 Hypervolume", " Chapter 6 Titanic Here we report the hypervolume achived by evaluating the performance of each solution wihtin the Pareto front on the test set of the titanic dataset. 6.1 Analysis setup # heart-disease data data &lt;- filter(testing, dataset == &quot;titanic&quot;) 6.2 Hypervolume volume_plotter(data,5) 6.2.1 Summary stats volume_summarize(data) ## # A tibble: 3 × 8 ## exp count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Evolved 20 0 0.0502 0.5 0.447 0.629 0.0894 ## 2 Calculated 20 0 0.00334 0.0143 0.0171 0.0448 0.0119 ## 3 None 20 0 0.00340 0.0126 0.0157 0.0430 0.0125 6.2.2 Kruskal-Wallis test Detected differences between weight strategies. kruskal.test(hv ~ exp, data = data) ## ## Kruskal-Wallis rank sum test ## ## data: hv by exp ## Kruskal-Wallis chi-squared = 39.658, df = 2, p-value = 2.445e-09 6.2.3 Pairwise wlcoxon test pairwise.wilcox.test(x = data$hv, g = data$exp, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: data$hv and data$exp ## ## Evolved Calculated ## Calculated 9e-08 - ## None 9e-08 0.74 ## ## P value adjustment method: bonferroni "],["us-crime.html", "Chapter 7 US Crime 7.1 Analysis setup 7.2 Hypervolume", " Chapter 7 US Crime Here we report the hypervolume achived by evaluating the performance of each solution wihtin the Pareto front on the test set of the us_crime dataset. 7.1 Analysis setup # heart-disease data data &lt;- filter(testing, dataset == &quot;us_crime&quot;) 7.2 Hypervolume volume_plotter(data,6) 7.2.1 Summary stats volume_summarize(data) ## # A tibble: 3 × 8 ## exp count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Evolved 20 0 0.407 0.5 0.505 0.807 0 ## 2 Calculated 20 0 0.0536 0.114 0.108 0.211 0.0322 ## 3 None 20 0 0.0534 0.113 0.107 0.203 0.0252 7.2.2 Kruskal-Wallis test Detected differences between weight strategies. kruskal.test(hv ~ exp, data = data) ## ## Kruskal-Wallis rank sum test ## ## data: hv by exp ## Kruskal-Wallis chi-squared = 39.978, df = 2, p-value = 2.084e-09 7.2.3 Pairwise wlcoxon test pairwise.wilcox.test(x = data$hv, g = data$exp, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: data$hv and data$exp ## ## Evolved Calculated ## Calculated 4.4e-08 - ## None 4.4e-08 1 ## ## P value adjustment method: bonferroni "],["compas-violent.html", "Chapter 8 Compas Violent 8.1 Analysis setup 8.2 Hypervolume", " Chapter 8 Compas Violent Here we report the hypervolume achived by evaluating the performance of each solution wihtin the Pareto front on the test set of the compas_violent dataset. 8.1 Analysis setup # heart-disease data data &lt;- filter(testing, dataset == &quot;compas_violent&quot;) 8.2 Hypervolume volume_plotter(data,7) 8.2.1 Summary stats volume_summarize(data) ## # A tibble: 3 × 8 ## exp count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Evolved 20 0 0.000741 0.00297 0.00319 0.00604 0.00185 ## 2 Calculated 20 0 0.000188 0.00215 0.00215 0.00435 0.00101 ## 3 None 20 0 0.000251 0.00210 0.00217 0.00489 0.000675 8.2.2 Kruskal-Wallis test Detected differences between weight strategies. kruskal.test(hv ~ exp, data = data) ## ## Kruskal-Wallis rank sum test ## ## data: hv by exp ## Kruskal-Wallis chi-squared = 6.7764, df = 2, p-value = 0.03377 8.2.3 Pairwise wlcoxon test pairwise.wilcox.test(x = data$hv, g = data$exp, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum exact test ## ## data: data$hv and data$exp ## ## Evolved Calculated ## Calculated 0.034 - ## None 0.039 1.000 ## ## P value adjustment method: bonferroni "],["nlsy.html", "Chapter 9 NLSY 9.1 Analysis setup 9.2 Hypervolume", " Chapter 9 NLSY Here we report the hypervolume achived by evaluating the performance of each solution wihtin the Pareto front on the test set of the nlsy dataset. 9.1 Analysis setup # heart-disease data data &lt;- filter(testing, dataset == &quot;nlsy&quot;) 9.2 Hypervolume volume_plotter(data,8) 9.2.1 Summary stats volume_summarize(data) ## # A tibble: 3 × 8 ## exp count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Evolved 20 0 0.294 0.471 0.468 0.578 0.0843 ## 2 Calculated 20 0 0.240 0.256 0.259 0.289 0.0177 ## 3 None 20 0 0.237 0.254 0.256 0.293 0.0186 9.2.2 Kruskal-Wallis test Detected differences between weight strategies. kruskal.test(hv ~ exp, data = data) ## ## Kruskal-Wallis rank sum test ## ## data: hv by exp ## Kruskal-Wallis chi-squared = 39.518, df = 2, p-value = 2.623e-09 9.2.3 Pairwise wlcoxon test pairwise.wilcox.test(x = data$hv, g = data$exp, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum exact test ## ## data: data$hv and data$exp ## ## Evolved Calculated ## Calculated 2.2e-11 - ## None 2.2e-11 0.82 ## ## P value adjustment method: bonferroni "],["compas.html", "Chapter 10 Compas 10.1 Analysis setup 10.2 Hypervolume", " Chapter 10 Compas Here we report the hypervolume achived by evaluating the performance of each solution wihtin the Pareto front on the test set of the compas dataset. 10.1 Analysis setup # heart-disease data data &lt;- filter(testing, dataset == &quot;compas&quot;) 10.2 Hypervolume volume_plotter(data,9) 10.2.1 Summary stats volume_summarize(data) ## # A tibble: 3 × 8 ## exp count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Evolved 20 0 0.00432 0.0111 0.0105 0.0164 0.00411 ## 2 Calculated 20 0 0.00217 0.00558 0.00546 0.00901 0.00258 ## 3 None 20 0 0.00231 0.00565 0.00548 0.00876 0.00299 10.2.2 Kruskal-Wallis test Detected differences between weight strategies. kruskal.test(hv ~ exp, data = data) ## ## Kruskal-Wallis rank sum test ## ## data: hv by exp ## Kruskal-Wallis chi-squared = 26.298, df = 2, p-value = 1.947e-06 10.2.3 Pairwise wlcoxon test pairwise.wilcox.test(x = data$hv, g = data$exp, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum exact test ## ## data: data$hv and data$exp ## ## Evolved Calculated ## Calculated 1.4e-06 - ## None 3.6e-06 1 ## ## P value adjustment method: bonferroni "],["speeddating.html", "Chapter 11 Speeddating 11.1 Analysis setup 11.2 Hypervolume", " Chapter 11 Speeddating Here we report the hypervolume achived by evaluating the performance of each solution wihtin the Pareto front on the test set of the speeddating dataset. 11.1 Analysis setup # heart-disease data data &lt;- filter(testing, dataset == &quot;speeddating&quot;) 11.2 Hypervolume volume_plotter(data,10) 11.2.1 Summary stats volume_summarize(data) ## # A tibble: 3 × 8 ## exp count na_cnt min median mean max IQR ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Evolved 20 0 0.229 0.5 0.486 0.5 0 ## 2 Calculated 20 0 0.0000388 0.000102 0.000114 0.000239 0.000121 ## 3 None 20 0 0.0000297 0.000109 0.000124 0.000255 0.000122 11.2.2 Kruskal-Wallis test Detected differences between weight strategies. kruskal.test(hv ~ exp, data = data) ## ## Kruskal-Wallis rank sum test ## ## data: hv by exp ## Kruskal-Wallis chi-squared = 40.672, df = 2, p-value = 1.473e-09 11.2.3 Pairwise wlcoxon test pairwise.wilcox.test(x = data$hv, g = data$exp, p.adjust.method = &quot;bonferroni&quot;, paired = FALSE, conf.int = FALSE, alternative = &#39;l&#39;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: data$hv and data$exp ## ## Evolved Calculated ## Calculated 1.7e-08 - ## None 1.7e-08 1 ## ## P value adjustment method: bonferroni "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
